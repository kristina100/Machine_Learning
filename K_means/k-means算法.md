# k-means算法

## 1. 流程

![image-20210805084502720](http://kristina.oss-cn-hangzhou.aliyuncs.com/img/image-20210805084502720.png)

## 2. 算法步骤

k-means采用距离作为相似性的评价指标，认为簇由靠近的对象组成，因此两个对象越近，相似度越高

**常见的距离公式**

* 欧式距离：
  $$
  d_{12}=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}
  $$

* 曼哈顿距离：
  $$
  d_{12}=|x_1-x_2|+|y_1-y_2|
  $$

* 切比雪夫距离：
  $$
  d_{12}=max(|x_1-x_2|,|y_1-y_2|)
  $$

* 余弦距离：
  $$
  cos\theta=\frac{x_1x_2+y_1y_2}{\sqrt{x_1^2+y_1^2}\sqrt{x_2^2+y_2^2}}
  $$

* jaccard相关系数：
  $$
  J(A,B)=\frac{|A\cap B|}{A\cup B}
  $$
  

* 相关系数：
  $$
  \rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}=\frac{E((X-EX)(Y-EY))}{\sqrt{D(X)}\sqrt{D(Y)}}
  $$
  



该算法的主要目的是找到紧凑且独立的簇，SSE最小的最优
$$
SSE=\sum_{i=1}^k\sum_{x\in C_i}dist(c_i,x)^2
$$
k表示聚类中心个数，c_i表示第几个聚类的中心点，dist表示欧几里得距离。

## 2. 算法核心思想

将N个样本{x1, ... , xN}划分到k个类{c1, ... ,ck}中，最小化目标函数：
$$
SSE=\sum_{j=1}^k\sum_{x_i \in C_j}dist(c_j,x_i)^2
$$
其中c1,...,ck是C1, ... ,Ck是质心，xi是划分到类Cj中的样本。

（1）从N个数据对象任意选择k个对象作为初始聚类中心记作：
$$
c_1^{(0)},c_2^{(0)},...,c_k^{(0)},其中上标t=0表示第0次迭代
$$
（2）对待分类的模式特征向量集{xi}中的模式逐个按最小距离原则划分给k类中的某一类。
$$
dist(c_i^{t},x_i)^2=min[disc(c_j^{(t)},x_i)^2],其中i=1,2,....N;\quad j=1,2,...,k,则x_i \in C_l^{(t+1)}
$$
（3）重新计算每个（有变化的）聚类的均值：
$$
c_j^{(t+1)}=\frac{1}{n_j^{(t+1)}}\sum_{x_i\in C_j^{(t+1)}}x_i,j=1,2,...,k
$$
为什么要取簇中的各点的均值作为下一状态的质心做出以下说明。

对第k个质心求解，最小化目标函数，即对SSE求导，令导数为0，并求解cj，如下所示：
$$
\frac{\part}{\part c_k}SSE=\frac{\part}{\part c_k}\sum_{i=1}^K\sum_{x \in C_i}(c_i-x)^2=\sum_{x\in C_k}(c_k-x_k)=0
$$
因此，簇的最小化SSE的最佳质心是簇中各点的均值。

（4）循环（2）（3），直到每个聚类不再发生变化为止。